{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Path to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'english-alphabets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check all folders in data path & join them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = []\n",
    "for i in os.listdir(path):\n",
    "    folders.append(os.path.join(path, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['english-alphabets/M',\n",
       " 'english-alphabets/X',\n",
       " 'english-alphabets/J',\n",
       " 'english-alphabets/V',\n",
       " 'english-alphabets/W',\n",
       " 'english-alphabets/Y',\n",
       " 'english-alphabets/G',\n",
       " 'english-alphabets/H',\n",
       " 'english-alphabets/S',\n",
       " 'english-alphabets/B',\n",
       " 'english-alphabets/L',\n",
       " 'english-alphabets/U',\n",
       " 'english-alphabets/D',\n",
       " 'english-alphabets/C',\n",
       " 'english-alphabets/A',\n",
       " 'english-alphabets/Z',\n",
       " 'english-alphabets/I',\n",
       " 'english-alphabets/R',\n",
       " 'english-alphabets/T',\n",
       " 'english-alphabets/K',\n",
       " 'english-alphabets/F',\n",
       " 'english-alphabets/E',\n",
       " 'english-alphabets/O',\n",
       " 'english-alphabets/P',\n",
       " 'english-alphabets/Q',\n",
       " 'english-alphabets/N']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For every pics in each folder, join them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = []\n",
    "for folder in folders:\n",
    "    for img_path in os.listdir(folder):\n",
    "        img_paths.append(os.path.join(folder, img_path))\n",
    "shuffle(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6759"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change images into Gray & change them into number arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in img_paths:\n",
    "    im = cv2.imread(i)\n",
    "    im = cv2.resize(im, (28,28))\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    im = cv2.equalizeHist(im)\n",
    "    im,thre = cv2.threshold(im,127,255, cv2.THRESH_BINARY)\n",
    "    np_im = np.array(thre)\n",
    "    data.append(np_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find labels in each Image path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = img_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'english-alphabets/I/5610.jpg'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.find('I')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in img_paths:\n",
    "    labels.append(i[18])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change them into Ascii codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [ord(i) for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,label in enumerate(labels):\n",
    "    if label == 88: # 88 is letter 'X' in Ascii code\n",
    "        value = index\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2cf40e0c18>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[value])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6759, 28, 28)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reshape(data.shape[0], data.shape[1] * data.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.1, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6083, 784)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = neighbors.KNeighborsClassifier(n_neighbors=5, weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check accuracy of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :89.50%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy :{:.2f}\".format(100*accuracy_score(test_labels, y_pred1)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          65       0.98      0.96      0.97        47\n",
      "          66       1.00      0.86      0.92        28\n",
      "          67       0.91      1.00      0.95        29\n",
      "          68       0.90      0.75      0.82        36\n",
      "          69       0.89      0.77      0.83        22\n",
      "          70       0.84      0.88      0.86        24\n",
      "          71       0.95      0.90      0.92        20\n",
      "          72       0.88      0.88      0.88        24\n",
      "          73       1.00      0.88      0.93        16\n",
      "          74       0.76      0.87      0.81        15\n",
      "          75       0.90      0.78      0.84        23\n",
      "          76       0.90      1.00      0.95        18\n",
      "          77       0.97      0.97      0.97        33\n",
      "          78       0.88      0.92      0.90        25\n",
      "          79       0.70      0.94      0.80        32\n",
      "          80       0.79      1.00      0.88        33\n",
      "          81       0.94      0.65      0.77        23\n",
      "          82       0.87      0.77      0.82        26\n",
      "          83       0.96      0.93      0.95        28\n",
      "          84       0.86      0.96      0.91        26\n",
      "          85       0.95      0.80      0.87        25\n",
      "          86       1.00      0.90      0.95        20\n",
      "          87       0.96      0.96      0.96        28\n",
      "          88       1.00      0.91      0.95        32\n",
      "          89       0.85      0.96      0.90        24\n",
      "          90       0.79      1.00      0.88        19\n",
      "\n",
      "    accuracy                           0.89       676\n",
      "   macro avg       0.90      0.89      0.89       676\n",
      "weighted avg       0.90      0.89      0.89       676\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, y_pred1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('finalized_model1.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use model & test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('finalized_model1.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test image, Pre-processing & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = '1.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img)\n",
    "img = cv2.resize(img, (700, 700))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('image', gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "cv2.imshow('image', blur)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "im,thre = cv2.threshold(gray,127,255,cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow('image', thre)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, hierachy = cv2.findContours(thre,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "rects = [cv2.boundingRect(cnt) for cnt in contours]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in contours:\n",
    "    (x,y,w,h) = cv2.boundingRect(i)\n",
    "    if w>15 and h>15:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),1)\n",
    "        roi= thre[y:y+h,x:x+w]\n",
    "        roi = cv2.resize(roi,(28,28))\n",
    "        #roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "        #cv2.imwrite(str(idx) + '.png', roi)\n",
    "        #idx += 1\n",
    "        roi = np.array(roi)\n",
    "        roi = roi.reshape(-1,(28*28))\n",
    "        pre = model.predict(roi)\n",
    "        pre = chr(pre)\n",
    "        cv2.putText(img, pre, (x , y),cv2.FONT_HERSHEY_DUPLEX,1,(255,0,0),1)\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = 'test_samples'\n",
    "images = []\n",
    "result_path = 'results'\n",
    "for i in os.listdir(test_samples):\n",
    "    images.append(os.path.join(test_samples, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0].find('2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in images:\n",
    "    label = i[13]\n",
    "    img = cv2.imread(i)\n",
    "    # Pre-processing\n",
    "    if img.shape[0] > 1000 or img.shape[1] > 1000:\n",
    "        img = cv2.resize(img, (700,700))\n",
    "    elif img.shape[0] < 300 or img.shape[1] < 300:\n",
    "        img = cv2.resize(img, (700,700))\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow('image', gray)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "    cv2.imshow('image', blur)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    im,thre = cv2.threshold(gray,125,255,cv2.THRESH_BINARY_INV)\n",
    "    cv2.imshow('image', thre)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    # find letters in images\n",
    "    contours, hierachy = cv2.findContours(thre,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rects = [cv2.boundingRect(cnt) for cnt in contours]\n",
    "    # predict letters\n",
    "    #idx = 0\n",
    "    for i in contours:\n",
    "        (x,y,w,h) = cv2.boundingRect(i)\n",
    "        if w > 15 and h > 15:\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),1)\n",
    "            new_img = gray[y:y+h,x:x+w]\n",
    "            new_img = cv2.resize(new_img,(28,28))\n",
    "            new_img = cv2.equalizeHist(new_img)\n",
    "            im,thre1 = cv2.threshold(new_img,127,255,cv2.THRESH_BINARY_INV)\n",
    "            #cv2.imwrite(str(idx) + '.png', new_img)\n",
    "            #idx += 1\n",
    "            np_img = np.array(thre1)\n",
    "            np_img = np_img.reshape(-1,(28*28))\n",
    "            pre = model.predict(np_img)\n",
    "            pre = chr(pre)\n",
    "            cv2.putText(img, pre, (x, y),cv2.FONT_HERSHEY_DUPLEX,1,(255,0,0),1)\n",
    "    # show results\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    # save results\n",
    "    cv2.imwrite(os.path.join(result_path, label + '.jpg'), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
